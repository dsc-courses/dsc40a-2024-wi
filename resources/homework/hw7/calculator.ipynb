{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Classifying Neutrino Signal from Noise in HPGe Detector</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will guide you through the second extra credit opportunity. Start out by reading the problem descriptions in the main homework assignment before you work through this notebook.\n",
    "\n",
    "We have three imports for this assignment. Please do not import any other packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Problem 6: Prediction Competition<h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your task is to modify the `predict` function given below. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(row):\n",
    "    '''Function that returns the predicted score for a given row of the waveform features\n",
    "    row will be a 1-d array of [tDrift50, tDrift90, tDrift100, blnoise, tslope, Energy, Current_Amplitude]\n",
    "    please change the return 0 to return a prediction score where:\n",
    "    * Higher score means the data point is more likely to be a signal (label 1)\n",
    "    * Lower score means the data point is more likely to be a noise (label 0)\n",
    "    Note the score doesn't have to be between 0 and 1\n",
    "    '''\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't modify the functions given below. This tests how well your predictions perform on a given dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_auc(label, score):\n",
    "    score = np.array(score)\n",
    "    label = np.array(label)\n",
    "    dsize = len(score)\n",
    "    minscore = min(score)\n",
    "    maxscore = max(score)\n",
    "    if minscore == maxscore:\n",
    "        return 0.5\n",
    "    tpr = []\n",
    "    fpr = []\n",
    "    sigscore = score[label==1]\n",
    "    bkgscore = score[label==0]\n",
    "    for thr in np.linspace(minscore,maxscore,10000):\n",
    "        tpr.append(np.sum(sigscore>=thr)/len(sigscore))\n",
    "        fpr.append(np.sum(bkgscore>=thr)/len(bkgscore))\n",
    "    \n",
    "    return np.trapz(tpr,1-np.array(fpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_AUC(df):\n",
    "    '''Compute ROC_AUC_score of the predictions corresponding to each row of the given dataframe'''\n",
    "    n = df.shape[0]\n",
    "    total_squared_error = 0\n",
    "    pred_array = []\n",
    "    label_array = np.array(df.get('Label'))\n",
    "    for i in np.arange(n):\n",
    "        pred_array += [predict(df.iloc[i].drop('Label'))]\n",
    "    return roc_auc(label_array, pred_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can test out your predictions on the training dataset provided. We'll also test your predictions on a hidden test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "waveforms = pd.read_csv('training_classification.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An example prediction\n",
    "example_row = waveforms.iloc[0].drop(\"Label\")\n",
    "predict(example_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(calculate_AUC(waveforms))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> To Submit </h3>\n",
    "\n",
    "In the top left corner, in the File menu, select Download as Python (.py). \n",
    "\n",
    "You must save your file as `calculator.py` for the Gradescope autograder to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
